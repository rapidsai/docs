

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>cuML API Reference &mdash; cuml 0.6.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script type="text/javascript" src="_static/jquery.js"></script>
        <script type="text/javascript" src="_static/underscore.js"></script>
        <script type="text/javascript" src="_static/doctools.js"></script>
        <script type="text/javascript" src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Welcome to cuML’s documentation!" href="index.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> cuml
          

          
          </a>

          
            
            
              <div class="version">
                0.6
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">cuML API Reference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#linear-regression">Linear Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#ridge-regression">Ridge Regression</a></li>
<li class="toctree-l2"><a class="reference internal" href="#stochastic-gradient-descent">Stochastic Gradient Descent</a></li>
<li class="toctree-l2"><a class="reference internal" href="#nearest-neighbors">Nearest Neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="#k-means-clustering">K-Means Clustering</a></li>
<li class="toctree-l2"><a class="reference internal" href="#dbscan">DBSCAN</a></li>
<li class="toctree-l2"><a class="reference internal" href="#kalman-filter">Kalman Filter</a></li>
<li class="toctree-l2"><a class="reference internal" href="#principal-component-analysis">Principal Component Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#truncated-svd">Truncated SVD</a></li>
<li class="toctree-l2"><a class="reference internal" href="#umap">UMAP</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">cuml</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>cuML API Reference</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/api.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="cuml-api-reference">
<h1>cuML API Reference<a class="headerlink" href="#cuml-api-reference" title="Permalink to this headline">¶</a></h1>
<div class="section" id="linear-regression">
<h2>Linear Regression<a class="headerlink" href="#linear-regression" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.LinearRegression">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">LinearRegression</code><a class="headerlink" href="#cuml.LinearRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>LinearRegression is a simple machine learning model where the response y is modelled by a
linear combination of the predictors in X.</p>
<p>cuML’s LinearRegression expects either a cuDF DataFrame or a NumPy matrix and provides 2
algorithms SVD and Eig to fit a linear model. SVD is more stable, but Eig (default)
is much more faster.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>algorithm</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘eig’ or ‘svd’ (default = ‘eig’)</span></dt>
<dd><p class="first last">Eig uses a eigendecomposition of the covariance matrix, and is much faster.
SVD is slower, but is guaranteed to be stable.</p>
</dd>
<dt><strong>fit_intercept</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd><p class="first last">If True, LinearRegression tries to correct for the global mean of y.
If False, the model expects that you have centered the data.</p>
</dd>
<dt><strong>normalize</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = False)</span></dt>
<dd><p class="first last">If True, the predictors in X will be normalized by dividing by it’s L2 norm.
If False, no scaling will be done.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>LinearRegression suffers from multicollinearity (when columns are correlated with each other),
and variance explosions from outliers. Consider using Ridge Regression to fix the multicollinearity 
problem,and consider maybe first DBSCAN to remove the outliers, or using leverage statistics to 
filter possible outliers.</p>
<p><strong>Applications of LinearRegression</strong></p>
<blockquote>
<div>LinearRegression is used in regression tasks where one wants to predict say sales or house prices.
It is also used in extrapolation or time series tasks, dynamic systems modelling and many other
machine learning tasks. This model should be first tried if the machine learning problem is a
regression task (predicting a continuous variable).</div></blockquote>
<p>For additional docs, see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">scikitlearn’s OLS</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cudf</span>

<span class="c1"># Both import methods supported</span>
<span class="kn">from</span> <span class="nn">cuml</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">from</span> <span class="nn">cuml.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>

<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">(</span><span class="n">fit_intercept</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">algorithm</span> <span class="o">=</span> <span class="s2">&quot;eig&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;col2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="p">)</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Coefficients:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;intercept:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>

<span class="n">X_new</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">X_new</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_new</span><span class="p">[</span><span class="s1">&#39;col2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Coefficients</span><span class="p">:</span>

            <span class="mi">0</span> <span class="mf">1.0000001</span>
            <span class="mi">1</span> <span class="mf">1.9999998</span>

<span class="n">Intercept</span><span class="p">:</span>
            <span class="mf">3.0</span>

<span class="n">Preds</span><span class="p">:</span>

            <span class="mi">0</span> <span class="mf">15.999999</span>
            <span class="mi">1</span> <span class="mf">14.999999</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>coef_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_features)</span></dt>
<dd><p class="first last">The estimated coefficients for the linear regression model.</p>
</dd>
<dt><strong>intercept_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The independent term. If <a href="#id7"><span class="problematic" id="id8">fit_intercept_</span></a> is False, will be 0.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.LinearRegression.fit" title="cuml.LinearRegression.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X,&nbsp;y)</td>
<td>Fit the model with X and y.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.LinearRegression.get_params" title="cuml.LinearRegression.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[,&nbsp;deep])</td>
<td>Sklearn style return parameter state</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.LinearRegression.predict" title="cuml.LinearRegression.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self,&nbsp;X)</td>
<td>Predicts the y for X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.LinearRegression.set_params" title="cuml.LinearRegression.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self,&nbsp;**params)</td>
<td>Sklearn style set parameter state to dictionary of params.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.LinearRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.LinearRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model with X and y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
<dt><strong>y: cuDF DataFrame</strong></dt>
<dd><p class="first last">Dense vector (floats or doubles) of shape (n_samples, 1)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.LinearRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>self</em>, <em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.LinearRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style return parameter state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>deep</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.LinearRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.LinearRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the y for X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y: cuDF DataFrame</strong></dt>
<dd><p class="first last">Dense vector (floats or doubles) of shape (n_samples, 1)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.LinearRegression.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>self</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.LinearRegression.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style set parameter state to dictionary of params.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict of new params</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="ridge-regression">
<h2>Ridge Regression<a class="headerlink" href="#ridge-regression" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.Ridge">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">Ridge</code><a class="headerlink" href="#cuml.Ridge" title="Permalink to this definition">¶</a></dt>
<dd><p>Ridge extends LinearRegression by providing L2 regularization on the coefficients when
predicting response y with a linear combination of the predictors in X. It can reduce
the variance of the predictors, and improves the conditioning of the problem.</p>
<p>cuML’s Ridge expects a cuDF DataFrame, and provides 3 algorithms SVD, Eig and CD to
fit a linear model. SVD is more stable, but Eig (default) is much more faster. CD uses
Coordinate Descent and can be faster if the data is large.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>alpha</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float or double</span></dt>
<dd><p class="first last">Regularization strength - must be a positive float. Larger values specify
stronger regularization. Array input will be supported later.</p>
</dd>
<dt><strong>solver</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘eig’ or ‘svd’ or ‘cd’ (default = ‘eig’)</span></dt>
<dd><p class="first last">Eig uses a eigendecomposition of the covariance matrix, and is much faster.
SVD is slower, but is guaranteed to be stable.
CD or Coordinate Descent is very fast and is suitable for large problems.</p>
</dd>
<dt><strong>fit_intercept</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd><p class="first last">If True, Ridge tries to correct for the global mean of y.
If False, the model expects that you have centered the data.</p>
</dd>
<dt><strong>normalize</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = False)</span></dt>
<dd><p class="first last">If True, the predictors in X will be normalized by dividing by it’s L2 norm.
If False, no scaling will be done.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Ridge provides L2 regularization. This means that the coefficients can shrink to become
very very small, but not zero. This can cause issues of interpretabiliy on the coefficients.
Consider using Lasso, or thresholding small coefficients to zero.</p>
<p><strong>Applications of Ridge</strong></p>
<blockquote>
<div>Ridge Regression is used in the same way as LinearRegression, but is used more frequently
as it does not suffer from multicollinearity issues. Ridge is used in insurance premium
prediction, stock market analysis and much more.</div></blockquote>
<p>For additional docs, see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">scikitlearn’s Ridge</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cudf</span>

<span class="c1"># Both import methods supported</span>
<span class="kn">from</span> <span class="nn">cuml</span> <span class="kn">import</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="nn">cuml.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>

<span class="n">alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">fit_intercept</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">normalize</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">solver</span> <span class="o">=</span> <span class="s2">&quot;eig&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;col2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">6.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">,</span> <span class="mf">9.0</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="p">)</span>

<span class="n">result_ridge</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_cudf</span><span class="p">,</span> <span class="n">y_cudf</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Coefficients:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">result_ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;intercept:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">result_ridge</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>

<span class="n">X_new</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">X_new</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X_new</span><span class="p">[</span><span class="s1">&#39;col2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">result_ridge</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Coefficients</span><span class="p">:</span>

            <span class="mi">0</span> <span class="mf">1.0000001</span>
            <span class="mi">1</span> <span class="mf">1.9999998</span>

<span class="n">Intercept</span><span class="p">:</span>
            <span class="mf">3.0</span>

<span class="n">Preds</span><span class="p">:</span>

            <span class="mi">0</span> <span class="mf">15.999999</span>
            <span class="mi">1</span> <span class="mf">14.999999</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>coef_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_features)</span></dt>
<dd><p class="first last">The estimated coefficients for the linear regression model.</p>
</dd>
<dt><strong>intercept_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The independent term. If <a href="#id9"><span class="problematic" id="id10">fit_intercept_</span></a> is False, will be 0.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.Ridge.fit" title="cuml.Ridge.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X,&nbsp;y)</td>
<td>Fit the model with X and y.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.Ridge.get_params" title="cuml.Ridge.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[,&nbsp;deep])</td>
<td>Sklearn style return parameter state</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.Ridge.predict" title="cuml.Ridge.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self,&nbsp;X)</td>
<td>Predicts the y for X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.Ridge.set_params" title="cuml.Ridge.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self,&nbsp;**params)</td>
<td>Sklearn style set parameter state to dictionary of params.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.Ridge.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em>, <em>y</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.Ridge.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model with X and y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
<dt><strong>y: cuDF DataFrame</strong></dt>
<dd><p class="first last">Dense vector (floats or doubles) of shape (n_samples, 1)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.Ridge.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>self</em>, <em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.Ridge.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style return parameter state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>deep</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.Ridge.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.Ridge.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the y for X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y: cuDF DataFrame</strong></dt>
<dd><p class="first last">Dense vector (floats or doubles) of shape (n_samples, 1)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.Ridge.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>self</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.Ridge.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style set parameter state to dictionary of params.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict of new params</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="stochastic-gradient-descent">
<h2>Stochastic Gradient Descent<a class="headerlink" href="#stochastic-gradient-descent" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.SGD">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">SGD</code><a class="headerlink" href="#cuml.SGD" title="Permalink to this definition">¶</a></dt>
<dd><p>Stochastic Gradient Descent is a very common machine learning algorithm where one optimizes
some cost function via gradient steps. This makes SGD very attractive for large problems
when the exact solution is hard or even impossible to find.</p>
<p>cuML’s SGD algorithm accepts a numpy matrix or a cuDF DataFrame as the input dataset.
The SGD algorithm currently works with linear regression, ridge regression and SVM models.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>loss</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘hinge’, ‘log’, ‘squared_loss’ (default = ‘squared_loss’)</span></dt>
<dd><p class="first last">‘hinge’ uses linear SVM   
‘log’ uses logistic regression
‘squared_loss’ uses linear regression</p>
</dd>
<dt><strong>penalty: ‘none’, ‘l1’, ‘l2’, ‘elasticnet’ (default = ‘none’)</strong></dt>
<dd><p class="first last">‘none’ does not perform any regularization
‘l1’ performs L1 norm (Lasso) which minimizes the sum of the abs value of coefficients
‘l2’ performs L2 norm (Ridge) which minimizes the sum of the square of the coefficients
‘elasticnet’ performs Elastic Net regularization which is a weighted average of L1 and L2 norms</p>
</dd>
<dt><strong>alpha: float (default = 0.0001)</strong></dt>
<dd><p class="first last">The constant value which decides the degree of regularization</p>
</dd>
<dt><strong>fit_intercept</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd><p class="first last">If True, the model tries to correct for the global mean of y.
If False, the model expects that you have centered the data.</p>
</dd>
<dt><strong>epochs</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 1000)</span></dt>
<dd><p class="first last">The number of times the model should iterate through the entire dataset during training (default = 1000)</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float (default = 1e-3)</span></dt>
<dd><p class="first last">The training process will stop if current_loss &gt; previous_loss - tol</p>
</dd>
<dt><strong>shuffle</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd><p class="first last">True, shuffles the training data after each epoch
False, does not shuffle the training data after each epoch</p>
</dd>
<dt><strong>eta0</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float (default = 0.0)</span></dt>
<dd><p class="first last">Initial learning rate</p>
</dd>
<dt><strong>power_t</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float (default = 0.5)</span></dt>
<dd><p class="first last">The exponent used for calculating the invscaling learning rate</p>
</dd>
<dt><strong>learning_rate</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘optimal’, ‘constant’, ‘invscaling’, ‘adaptive’ (default = ‘constant’)</span></dt>
<dd><p class="first last">optimal option supported in the next version
constant keeps the learning rate constant
adaptive changes the learning rate if the training loss or the validation accuracy does not improve for n_iter_no_change epochs.
The old learning rate is generally divide by 5</p>
</dd>
<dt><strong>n_iter_no_change</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 5)</span></dt>
<dd><p class="first last">the number of epochs to train without any imporvement in the model</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>For additional docs, see <a href="#id1"><span class="problematic" id="id2">`</span></a>scikitlearn’s OLS &lt;<a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html">https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html</a>&gt;</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">from</span> <span class="nn">cuml.solvers</span> <span class="kn">import</span> <span class="n">SGD</span> <span class="k">as</span> <span class="n">cumlSGD</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">X</span><span class="p">[</span><span class="s1">&#39;col2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="n">pred_data</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">pred_data</span><span class="p">[</span><span class="s1">&#39;col1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">datatype</span><span class="p">)</span>
<span class="n">pred_data</span><span class="p">[</span><span class="s1">&#39;col2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">datatype</span><span class="p">)</span>

<span class="n">cu_sgd</span> <span class="o">=</span> <span class="n">cumlSGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">lrate</span><span class="p">,</span> <span class="n">eta0</span><span class="o">=</span><span class="mf">0.005</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span>
                <span class="n">fit_intercept</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">tol</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="n">penalty</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">)</span>

<span class="n">cu_sgd</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">cu_pred</span> <span class="o">=</span> <span class="n">cu_sgd</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">pred_data</span><span class="p">)</span><span class="o">.</span><span class="n">to_array</span><span class="p">()</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot; cuML intercept : &quot;</span><span class="p">,</span> <span class="n">cu_sgd</span><span class="o">.</span><span class="n">intercept_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot; cuML coef : &quot;</span><span class="p">,</span> <span class="n">cu_sgd</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;cuML predictions : &quot;</span><span class="p">,</span> <span class="n">cu_pred</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">cuML</span> <span class="n">intercept</span> <span class="p">:</span>  <span class="mf">0.004561662673950195</span>
<span class="n">cuML</span> <span class="n">coef</span> <span class="p">:</span>  <span class="mi">0</span>      <span class="mf">0.9834546</span>
            <span class="mi">1</span>    <span class="mf">0.010128272</span>
           <span class="n">dtype</span><span class="p">:</span> <span class="n">float32</span>
<span class="n">cuML</span> <span class="n">predictions</span> <span class="p">:</span>  <span class="p">[</span><span class="mf">3.0055666</span> <span class="mf">2.0221121</span><span class="p">]</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.SGD.fit" title="cuml.SGD.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a></td>
<td>Fit the model with X and y.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.SGD.predict" title="cuml.SGD.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a></td>
<td>Predicts the y for X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.SGD.predictClass" title="cuml.SGD.predictClass"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predictClass</span></code></a></td>
<td>Predicts the y for X.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.SGD.fit">
<code class="descname">fit</code><a class="headerlink" href="#cuml.SGD.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model with X and y.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
<dt><strong>y: cuDF DataFrame</strong></dt>
<dd><p class="first last">Dense vector (floats or doubles) of shape (n_samples, 1)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.SGD.predict">
<code class="descname">predict</code><a class="headerlink" href="#cuml.SGD.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the y for X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y: cuDF DataFrame</strong></dt>
<dd><p class="first last">Dense vector (floats or doubles) of shape (n_samples, 1)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.SGD.predictClass">
<code class="descname">predictClass</code><a class="headerlink" href="#cuml.SGD.predictClass" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts the y for X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y: cuDF DataFrame</strong></dt>
<dd><p class="first last">Dense vector (floats or doubles) of shape (n_samples, 1)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="nearest-neighbors">
<h2>Nearest Neighbors<a class="headerlink" href="#nearest-neighbors" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.NearestNeighbors">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">NearestNeighbors</code><a class="headerlink" href="#cuml.NearestNeighbors" title="Permalink to this definition">¶</a></dt>
<dd><p>NearestNeighbors is a unsupervised algorithm where if one wants to find the “closest”
datapoint(s) to new unseen data, one can calculate a suitable “distance” between 
each and every point, and return the top K datapoints which have the smallest distance to it.</p>
<p>cuML’s KNN expects a cuDF DataFrame or a Numpy Array (where automatic chunking will be done
in to a Numpy Array in a future release), and fits a special data structure first to
approximate the distance calculations, allowing our querying times to be O(plogn)
and not the brute force O(np) [where p = no(features)]:</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_neighbors: int (default = 5)</strong></dt>
<dd><p class="first last">The top K closest datapoints you want the algorithm to return. If this number is large,
then expect the algorithm to run slower.</p>
</dd>
<dt><strong>should_downcast</strong> <span class="classifier-delimiter">:</span> <span class="classifier">bool (default = False)</span></dt>
<dd><p class="first last">Currently only single precision is supported in the underlying undex. Setting this to
true will allow single-precision input arrays to be automatically downcasted to single
precision. Default = False.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>NearestNeighbors is a generative model. This means the data X has to be stored in order
for inference to occur.</p>
<p><strong>Applications of NearestNeighbors</strong></p>
<blockquote>
<div>Applications of NearestNeighbors include recommendation systems where content or colloborative
filtering is used. Since NearestNeighbors is a relatively simple generative model, it is also
used in data visualization and regression / classification tasks.</div></blockquote>
<p>For an additional example see <a class="reference external" href="https://github.com/rapidsai/notebook/blob/master/python/notebooks/knn_demo.ipynb">the NearestNeighbors notebook</a>.</p>
<p>For additional docs, see <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors">scikitlearn’s NearestNeighbors</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">from</span> <span class="nn">cuml.neighbors</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">np_float</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
  <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="c1"># Point 1</span>
  <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="c1"># Point 2</span>
  <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">]</span>  <span class="c1"># Point 3</span>
<span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>

<span class="n">gdf_float</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;dim_0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">np_float</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;dim_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">np_float</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;dim_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">np_float</span><span class="p">[:,</span><span class="mi">2</span><span class="p">])</span>

<span class="k">print</span><span class="p">(</span><span class="s1">&#39;n_samples = 3, n_dims = 3&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">)</span>

<span class="n">nn_float</span> <span class="o">=</span> <span class="n">NearestNeighbors</span><span class="p">()</span>
<span class="n">nn_float</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">)</span>
<span class="n">distances</span><span class="p">,</span><span class="n">indices</span> <span class="o">=</span> <span class="n">nn_float</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">,</span><span class="n">k</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span> <span class="c1">#get 3 nearest neighbors</span>

<span class="k">print</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cudf</span>

<span class="c1"># Both import methods supported</span>
<span class="c1"># from cuml.neighbors import NearestNeighbors</span>
<span class="kn">from</span> <span class="nn">cuml</span> <span class="kn">import</span> <span class="n">NearestNeighbors</span>

<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">n_dims</span> <span class="o">=</span> <span class="mi">3</span>

<span class="n">dim_0</span> <span class="n">dim_1</span> <span class="n">dim_2</span>

<span class="mi">0</span>   <span class="mf">1.0</span>   <span class="mf">2.0</span>   <span class="mf">3.0</span>
<span class="mi">1</span>   <span class="mf">1.0</span>   <span class="mf">2.0</span>   <span class="mf">4.0</span>
<span class="mi">2</span>   <span class="mf">2.0</span>   <span class="mf">2.0</span>   <span class="mf">4.0</span>

<span class="c1"># indices:</span>

         <span class="n">index_neighbor_0</span> <span class="n">index_neighbor_1</span> <span class="n">index_neighbor_2</span>
<span class="mi">0</span>                <span class="mi">0</span>                <span class="mi">1</span>                <span class="mi">2</span>
<span class="mi">1</span>                <span class="mi">1</span>                <span class="mi">0</span>                <span class="mi">2</span>
<span class="mi">2</span>                <span class="mi">2</span>                <span class="mi">1</span>                <span class="mi">0</span>
<span class="c1"># distances:</span>

         <span class="n">distance_neighbor_0</span> <span class="n">distance_neighbor_1</span> <span class="n">distance_neighbor_2</span>
<span class="mi">0</span>                 <span class="mf">0.0</span>                 <span class="mf">1.0</span>                 <span class="mf">2.0</span>
<span class="mi">1</span>                 <span class="mf">0.0</span>                 <span class="mf">1.0</span>                 <span class="mf">1.0</span>
<span class="mi">2</span>                 <span class="mf">0.0</span>                 <span class="mf">1.0</span>                 <span class="mf">2.0</span>
</pre></div>
</div>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.NearestNeighbors.fit" title="cuml.NearestNeighbors.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X)</td>
<td>Fit GPU index for performing nearest neighbor queries.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.NearestNeighbors.kneighbors" title="cuml.NearestNeighbors.kneighbors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">kneighbors</span></code></a>(self,&nbsp;X[,&nbsp;k])</td>
<td>Query the GPU index for the k nearest neighbors of row vectors in X.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="cuml.NearestNeighbors.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.NearestNeighbors.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit GPU index for performing nearest neighbor queries.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame or numpy ndarray</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="cuml.NearestNeighbors.kneighbors">
<code class="descname">kneighbors</code><span class="sig-paren">(</span><em>self</em>, <em>X</em>, <em>k=None</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.NearestNeighbors.kneighbors" title="Permalink to this definition">¶</a></dt>
<dd><p>Query the GPU index for the k nearest neighbors of row vectors in X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame or numpy ndarray</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
<dt><strong>k: Integer</strong></dt>
<dd><p class="first last">The number of neighbors</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>distances: cuDF DataFrame or numpy ndarray</strong></dt>
<dd><p class="first last">The distances of the k-nearest neighbors for each column vector in X</p>
</dd>
<dt><strong>indices: cuDF DataFrame of numpy ndarray</strong></dt>
<dd><p class="first last">The indices of the k-nearest neighbors for each column vector in X</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="k-means-clustering">
<h2>K-Means Clustering<a class="headerlink" href="#k-means-clustering" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.KMeans">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">KMeans</code><a class="headerlink" href="#cuml.KMeans" title="Permalink to this definition">¶</a></dt>
<dd><p>KMeans is a basic but powerful clustering method which is optimized via Expectation Maximization.
It randomnly selects K data points in X, and computes which samples are close to these points.
For every cluster of points, a mean is computed (hence the name), and this becomes the new
centroid.</p>
<p>cuML’s KMeans expects a cuDF DataFrame, and supports the fast KMeans++ intialization method. This
method is more stable than randomnly selecting K points.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_clusters</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 8)</span></dt>
<dd><p class="first last">The number of centroids or clusters you want.</p>
</dd>
<dt><strong>max_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 300)</span></dt>
<dd><p class="first last">The more iterations of EM, the more accurate, but slower.</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float (default = 1e-4)</span></dt>
<dd><p class="first last">Stopping criterion when centroid means do not change much.</p>
</dd>
<dt><strong>verbose</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = 0)</span></dt>
<dd><p class="first last">If True, prints diagnositc information.</p>
</dd>
<dt><strong>random_state</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 1)</span></dt>
<dd><p class="first last">If you want results to be the same when you restart Python, select a state.</p>
</dd>
<dt><strong>precompute_distances</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = ‘auto’)</span></dt>
<dd><p class="first last">Not supported yet.</p>
</dd>
<dt><strong>init</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘kmeans++’</span></dt>
<dd><p class="first last">Uses fast and stable kmeans++ intialization. More options will be supported later.</p>
</dd>
<dt><strong>n_init</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 1)</span></dt>
<dd><p class="first last">Number of times intialization is run. More is slower, but can be better.</p>
</dd>
<dt><strong>algorithm</strong> <span class="classifier-delimiter">:</span> <span class="classifier">“auto”</span></dt>
<dd><p class="first last">Currently uses full EM, but will support others later.</p>
</dd>
<dt><strong>n_gpu</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 1)</span></dt>
<dd><p class="first last">Number of GPUs to use. If -1 is used, uses all GPUs. More usage is faster.</p>
</dd>
<dt><strong>gpu_id</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 0)</span></dt>
<dd><p class="first last">Which GPU to use if n_gpu == 1.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>KMeans requires n_clusters to be specified. This means one needs to approximately guess or know
how many clusters a dataset has. If one is not sure, one can start with a small number of clusters, and 
visualize the resulting clusters with PCA, UMAP or T-SNE, and verify that they look appropriate.</p>
<p><strong>Applications of KMeans</strong></p>
<blockquote>
<div>The biggest advantage of KMeans is its speed and simplicity. That is why KMeans is many practitioner’s
first choice of a clustering algorithm. KMeans has been extensively used when the number of clusters is
approximately known, such as in big data clustering tasks, image segmentation and medical clustering.</div></blockquote>
<p>For additional docs, see <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">scikitlearn’s Kmeans</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Both import methods supported</span>
<span class="kn">from</span> <span class="nn">cuml</span> <span class="kn">import</span> <span class="n">KMeans</span>
<span class="kn">from</span> <span class="nn">cuml.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>

<span class="k">def</span> <span class="nf">np2cudf</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="c1"># convert numpy array to cuDF dataframe</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;fea</span><span class="si">%d</span><span class="s1">&#39;</span><span class="o">%</span><span class="n">i</span><span class="p">:</span><span class="n">df</span><span class="p">[:,</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])})</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">c</span><span class="p">,</span><span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
      <span class="n">pdf</span><span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">c</span><span class="p">)]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">column</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">pdf</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">3.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">]],</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">np2cudf</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;input:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;Calling fit&quot;</span><span class="p">)</span>
<span class="n">kmeans_float</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_gpu</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">kmeans_float</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s2">&quot;labels:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">kmeans_float</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s2">&quot;cluster_centers:&quot;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">kmeans_float</span><span class="o">.</span><span class="n">cluster_centers_</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">input</span><span class="p">:</span>

     <span class="mi">0</span>    <span class="mi">1</span>
 <span class="mi">0</span>  <span class="mf">1.0</span>  <span class="mf">1.0</span>
 <span class="mi">1</span>  <span class="mf">1.0</span>  <span class="mf">2.0</span>
 <span class="mi">2</span>  <span class="mf">3.0</span>  <span class="mf">2.0</span>
 <span class="mi">3</span>  <span class="mf">4.0</span>  <span class="mf">3.0</span>

<span class="n">Calling</span> <span class="n">fit</span>

<span class="n">labels</span><span class="p">:</span>

   <span class="mi">0</span>    <span class="mi">1</span>
   <span class="mi">1</span>    <span class="mi">1</span>
   <span class="mi">2</span>    <span class="mi">0</span>
   <span class="mi">3</span>    <span class="mi">0</span>

<span class="n">cluster_centers</span><span class="p">:</span>

   <span class="mi">0</span>    <span class="mi">1</span>
<span class="mi">0</span>  <span class="mf">3.5</span>  <span class="mf">2.5</span>
<span class="mi">1</span>  <span class="mf">1.0</span>  <span class="mf">1.5</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>cluster_centers_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The coordinates of the final clusters. This represents of “mean” of each data cluster.</p>
</dd>
<dt><strong>labels_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">Which cluster each datapoint belongs to.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.KMeans.fit" title="cuml.KMeans.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X)</td>
<td>Compute k-means clustering with X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.KMeans.fit_predict" title="cuml.KMeans.fit_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_predict</span></code></a>(self,&nbsp;X)</td>
<td>Compute cluster centers and predict cluster index for each sample.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.KMeans.fit_transform" title="cuml.KMeans.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(self,&nbsp;input_gdf)</td>
<td>Compute clustering and transform input_gdf to cluster-distance space.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.KMeans.get_params" title="cuml.KMeans.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[,&nbsp;deep])</td>
<td>Sklearn style return parameter state</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.KMeans.predict" title="cuml.KMeans.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self,&nbsp;X)</td>
<td>Predict the closest cluster each sample in X belongs to.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.KMeans.set_params" title="cuml.KMeans.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self,&nbsp;**params)</td>
<td>Sklearn style set parameter state to dictionary of params.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.KMeans.transform" title="cuml.KMeans.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(self,&nbsp;X)</td>
<td>Transform X to a cluster-distance space.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.KMeans.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KMeans.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute k-means clustering with X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.KMeans.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KMeans.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute cluster centers and predict cluster index for each sample.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.KMeans.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>self</em>, <em>input_gdf</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KMeans.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute clustering and transform input_gdf to cluster-distance space.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>input_gdf</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.KMeans.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>self</em>, <em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KMeans.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style return parameter state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>deep</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.KMeans.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KMeans.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict the closest cluster each sample in X belongs to.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.KMeans.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>self</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KMeans.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style set parameter state to dictionary of params.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict of new params</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.KMeans.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KMeans.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X to a cluster-distance space.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="dbscan">
<h2>DBSCAN<a class="headerlink" href="#dbscan" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.DBSCAN">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">DBSCAN</code><a class="headerlink" href="#cuml.DBSCAN" title="Permalink to this definition">¶</a></dt>
<dd><p>DBSCAN is a very powerful yet fast clustering technique that finds clusters where
data is concentrated. This allows DBSCAN to generalize to many problems if the
datapoints tend to congregate in larger groups.</p>
<p>cuML’s DBSCAN expects a cuDF DataFrame, and constructs an adjacency graph to compute
the distances between close neighbours.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>eps</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float (default = 0.5)</span></dt>
<dd><p class="first last">The maximum distance between 2 points such they reside in the same neighborhood.</p>
</dd>
<dt><strong>min_samples</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 5)</span></dt>
<dd><p class="first last">The number of samples in a neighborhood such that this group can be considered as
an important core point (including the point itself).</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>DBSCAN is very sensitive to the distance metric it is used with, and a large assumption
is that datapoints need to be concentrated in groups for clusters to be constructed.</p>
<p><strong>Applications of DBSCAN</strong></p>
<blockquote>
<div>DBSCAN’s main benefit is that the number of clusters is not a hyperparameter, and that
it can find non-linearly shaped clusters. This also allows DBSCAN to be robust to noise.
DBSCAN has been applied to analyzing particle collisons in the Large Hadron Collider,
customer segmentation in marketing analyses, and much more.</div></blockquote>
<p>For an additional example, see <a class="reference external" href="https://github.com/rapidsai/notebooks/blob/master/cuml/dbscan_demo.ipynb">the DBSCAN notebook</a>.
For additional docs, see <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html">scikitlearn’s DBSCAN</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Both import methods supported</span>
<span class="kn">from</span> <span class="nn">cuml</span> <span class="kn">import</span> <span class="n">DBSCAN</span>
<span class="kn">from</span> <span class="nn">cuml.cluster</span> <span class="kn">import</span> <span class="n">DBSCAN</span>

<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">gdf_float</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">dbscan_float</span> <span class="o">=</span> <span class="n">DBSCAN</span><span class="p">(</span><span class="n">eps</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">min_samples</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">dbscan_float</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">dbscan_float</span><span class="o">.</span><span class="n">labels_</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span>    <span class="mi">0</span>
<span class="mi">1</span>    <span class="mi">1</span>
<span class="mi">2</span>    <span class="mi">2</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>labels_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">Which cluster each datapoint belongs to. Noisy samples are labeled as -1.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.DBSCAN.fit" title="cuml.DBSCAN.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X)</td>
<td>Perform DBSCAN clustering from features.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.DBSCAN.fit_predict" title="cuml.DBSCAN.fit_predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_predict</span></code></a>(self,&nbsp;X)</td>
<td>Performs clustering on input_gdf and returns cluster labels.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.DBSCAN.get_params" title="cuml.DBSCAN.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[,&nbsp;deep])</td>
<td>Sklearn style return parameter state</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.DBSCAN.set_params" title="cuml.DBSCAN.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self,&nbsp;**params)</td>
<td>Sklearn style set parameter state to dictionary of params.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.DBSCAN.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.DBSCAN.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform DBSCAN clustering from features.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.DBSCAN.fit_predict">
<code class="descname">fit_predict</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.DBSCAN.fit_predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs clustering on input_gdf and returns cluster labels.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features),</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF Series, shape (n_samples)</span></dt>
<dd><p class="first last">cluster labels</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.DBSCAN.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>self</em>, <em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.DBSCAN.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style return parameter state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>deep</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.DBSCAN.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>self</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.DBSCAN.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style set parameter state to dictionary of params.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict of new params</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="kalman-filter">
<h2>Kalman Filter<a class="headerlink" href="#kalman-filter" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.KalmanFilter">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">KalmanFilter</code><a class="headerlink" href="#cuml.KalmanFilter" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements a Kalman filter. You are responsible for setting the
various state variables to reasonable values; defaults  will
not give you a functional filter.
After construction the filter will have default matrices created for you,
but you must specify the values for each.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>dim_x</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Number of state variables for the Kalman filter.
This is used to set the default size of P, Q, and u</p>
</dd>
<dt><strong>dim_z</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Number of of measurement inputs.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">cuml</span> <span class="k">import</span> <span class="n">KalmanFilter</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">KalmanFilter</span><span class="p">(</span><span class="n">dim_x</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim_z</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">f</span><span class="o">.</span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">2.</span><span class="p">],</span>    <span class="c1"># position</span>
                <span class="p">[</span><span class="mf">0.</span><span class="p">]])</span>   <span class="c1"># velocity</span>
<span class="n">f</span><span class="o">.</span><span class="n">F</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span><span class="mf">1.</span><span class="p">]])</span>
<span class="n">f</span><span class="o">.</span><span class="n">H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span><span class="mf">0.</span><span class="p">]])</span>
<span class="n">f</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1000.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span>   <span class="mf">0.</span><span class="p">,</span> <span class="mf">1000.</span><span class="p">]</span> <span class="p">])</span>
<span class="n">f</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>
</div>
<p>Now just perform the standard predict/update loop:</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">while</span> <span class="n">some_condition_is_true</span><span class="p">:</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">i</span><span class="p">])</span>
    <span class="n">f</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span>
    <span class="n">f</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>x</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array, numpy array or cuDF series (dim_x, 1),</span></dt>
<dd><p class="first last">Current state estimate. Any call to update() or predict() updates
this variable.</p>
</dd>
<dt><strong>P</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array, numpy array or cuDF dataframe(dim_x, dim_x)</span></dt>
<dd><p class="first last">Current state covariance matrix. Any call to update() or predict()
updates this variable.</p>
</dd>
<dt><strong>x_prior</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array, numpy array or cuDF series(dim_x, 1)</span></dt>
<dd><p class="first last">Prior (predicted) state estimate. The <a href="#id3"><span class="problematic" id="id4">*</span></a>_prior and <a href="#id5"><span class="problematic" id="id6">*</span></a>_post attributes
are for convienence; they store the  prior and posterior of the
current epoch. Read Only.</p>
</dd>
<dt><strong>P_prior</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array, numpy array or cuDF dataframe(dim_x, dim_x)</span></dt>
<dd><p class="first last">Prior (predicted) state covariance matrix. Read Only.</p>
</dd>
<dt><strong>x_post</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array, numpy array or cuDF series(dim_x, 1)</span></dt>
<dd><p class="first last">Posterior (updated) state estimate. Read Only.</p>
</dd>
<dt><strong>P_post</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array, numpy array or cuDF dataframe(dim_x, dim_x)</span></dt>
<dd><p class="first last">Posterior (updated) state covariance matrix. Read Only.</p>
</dd>
<dt><strong>z</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array or cuDF series (dim_x, 1)</span></dt>
<dd><p class="first last">Last measurement used in update(). Read only.</p>
</dd>
<dt><strong>R</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array(dim_z, dim_z)</span></dt>
<dd><p class="first last">Measurement noise matrix</p>
</dd>
<dt><strong>Q</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array(dim_x, dim_x)</span></dt>
<dd><p class="first last">Process noise matrix</p>
</dd>
<dt><strong>F</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array()</span></dt>
<dd><p class="first last">State Transition matrix</p>
</dd>
<dt><strong>H</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array(dim_z, dim_x)</span></dt>
<dd><p class="first last">Measurement function</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array</span></dt>
<dd><p class="first last">Residual of the update step. Read only.</p>
</dd>
<dt><strong>K</strong> <span class="classifier-delimiter">:</span> <span class="classifier">numba device array(dim_x, dim_z)</span></dt>
<dd><p class="first last">Kalman gain of the update step. Read only.</p>
</dd>
<dt><strong>precision: ‘single’ or ‘double’</strong></dt>
<dd><p class="first last">Whether the Kalman Filter uses single or double precision</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.KalmanFilter.predict" title="cuml.KalmanFilter.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a>(self[,&nbsp;B,&nbsp;F,&nbsp;Q])</td>
<td>Predict next state (prior) using the Kalman filter state propagation equations.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.KalmanFilter.update" title="cuml.KalmanFilter.update"><code class="xref py py-obj docutils literal notranslate"><span class="pre">update</span></code></a>(self,&nbsp;z[,&nbsp;R,&nbsp;H])</td>
<td>Add a new measurement (z) to the Kalman filter.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.KalmanFilter.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>self</em>, <em>B=None</em>, <em>F=None</em>, <em>Q=None</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KalmanFilter.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Predict next state (prior) using the Kalman filter state propagation
equations.
Parameters
———-
u : np.array</p>
<blockquote>
<div>Optional control vector. If not <cite>None</cite>, it is multiplied by B
to create the control input into the system.</div></blockquote>
<dl class="docutils">
<dt>B <span class="classifier-delimiter">:</span> <span class="classifier">np.array(dim_x, dim_z), or None</span></dt>
<dd>Optional control transition matrix; a value of None
will cause the filter to use <cite>self.B</cite>.</dd>
<dt>F <span class="classifier-delimiter">:</span> <span class="classifier">np.array(dim_x, dim_x), or None</span></dt>
<dd>Optional state transition matrix; a value of None
will cause the filter to use <cite>self.F</cite>.</dd>
<dt>Q <span class="classifier-delimiter">:</span> <span class="classifier">np.array(dim_x, dim_x), scalar, or None</span></dt>
<dd>Optional process noise matrix; a value of None will cause the
filter to use <cite>self.Q</cite>.</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="cuml.KalmanFilter.update">
<code class="descname">update</code><span class="sig-paren">(</span><em>self</em>, <em>z</em>, <em>R=None</em>, <em>H=None</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.KalmanFilter.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Add a new measurement (z) to the Kalman filter.
If z is None, nothing is computed. However, x_post and P_post are
updated with the prior (x_prior, P_prior), and self.z is set to None.
Parameters
———-
z : (dim_z, 1): array_like</p>
<blockquote>
<div>measurement for this update. z can be a scalar if dim_z is 1,
otherwise it must be convertible to a column vector.</div></blockquote>
<dl class="docutils">
<dt>R <span class="classifier-delimiter">:</span> <span class="classifier">np.array, scalar, or None</span></dt>
<dd>Optionally provide R to override the measurement noise for this
one call, otherwise  self.R will be used.</dd>
<dt>H <span class="classifier-delimiter">:</span> <span class="classifier">np.array, or None</span></dt>
<dd>Optionally provide H to override the measurement function for this
one call, otherwise self.H will be used.</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="principal-component-analysis">
<h2>Principal Component Analysis<a class="headerlink" href="#principal-component-analysis" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.PCA">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">PCA</code><a class="headerlink" href="#cuml.PCA" title="Permalink to this definition">¶</a></dt>
<dd><p>PCA (Principal Component Analysis) is a fundamental dimensionality reduction technique used to
combine features in X in linear combinations such that each new component captures the most
information or variance of the data. N_components is usually small, say at 3, where it can be
used for data visualization, data compression and exploratory analysis.</p>
<p>cuML’s PCA expects a cuDF DataFrame, and provides 2 algorithms Full and Jacobi.
Full (default) uses a full eigendecomposition then selects the top K eigenvectors. 
The Jacobi algorithm is much faster as it iteratively tries to correct the top K eigenvectors,
but might be less accurate.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_components</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 1)</span></dt>
<dd><p class="first last">The number of top K singular vectors / values you want. Must be &lt;= number(columns).</p>
</dd>
<dt><strong>svd_solver</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘full’ or ‘jacobi’ or ‘auto’ (default = ‘full’)</span></dt>
<dd><p class="first last">Full uses a eigendecomposition of the covariance matrix then discards components.
Jacobi is much faster as it iteratively corrects, but is less accurate.</p>
</dd>
<dt><strong>iterated_power</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 15)</span></dt>
<dd><p class="first last">Used in Jacobi solver. The more iterations, the more accurate, but the slower.</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float (default = 1e-7)</span></dt>
<dd><p class="first last">Used if algorithm = “jacobi”. The smaller the tolerance, the more accurate,
but the more slower the algorithm will get to converge.</p>
</dd>
<dt><strong>random_state</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int / None (default = None)</span></dt>
<dd><p class="first last">If you want results to be the same when you restart Python, select a state.</p>
</dd>
<dt><strong>copy</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd><p class="first last">If True, then copies data then removes mean from data. False might cause data to be
overwritten with its mean centered version.</p>
</dd>
<dt><strong>whiten</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = False)</span></dt>
<dd><p class="first last">If True, de-correlates the components. This is done by dividing them by the corresponding
singular values then multiplying by sqrt(n_samples). Whitening allows each component
to have unit variance and removes multi-collinearity. It might be beneficial for downstream
tasks like LinearRegression where correlated features cause problems.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>PCA considers linear combinations of features, specifically those that maximise global
variance structure. This means PCA is fantastic for global structure analyses, but weak
for local relationships. Consider UMAP or T-SNE for a locally important embedding.</p>
<p><strong>Applications of PCA</strong></p>
<blockquote>
<div>PCA is used extensively in practice for data visualization and data compression. It has been used
to visualize extremely large word embeddings like Word2Vec and GloVe in 2 or 3 dimensions, large
datasets of everyday objects and images, and used to distinguish between cancerous cells from 
healthy cells.</div></blockquote>
<p>For an additional example see <a class="reference external" href="https://github.com/rapidsai/notebooks/blob/master/cuml/pca_demo.ipynb">the PCA notebook</a>. 
For additional docs, see <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html">scikitlearn’s PCA</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Both import methods supported</span>
<span class="kn">from</span> <span class="nn">cuml</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">from</span> <span class="nn">cuml.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">gdf_float</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">pca_float</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">pca_float</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;components: {pca_float.components_}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;explained variance: {pca_float.explained_variance_}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;explained variance ratio: {pca_float.explained_variance_ratio_}&#39;</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;singular values: {pca_float.singular_values_}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;mean: {pca_float.mean_}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;noise variance: {pca_float.noise_variance_}&#39;</span><span class="p">)</span>

<span class="n">trans_gdf_float</span> <span class="o">=</span> <span class="n">pca_float</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Inverse: {trans_gdf_float}&#39;</span><span class="p">)</span>

<span class="n">input_gdf_float</span> <span class="o">=</span> <span class="n">pca_float</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">trans_gdf_float</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Input: {input_gdf_float}&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">components</span><span class="p">:</span>
            <span class="mi">0</span>           <span class="mi">1</span>           <span class="mi">2</span>
            <span class="mi">0</span>  <span class="mf">0.69225764</span>  <span class="o">-</span><span class="mf">0.5102837</span> <span class="o">-</span><span class="mf">0.51028395</span>
            <span class="mi">1</span> <span class="o">-</span><span class="mf">0.72165036</span> <span class="o">-</span><span class="mf">0.48949987</span>  <span class="o">-</span><span class="mf">0.4895003</span>

<span class="n">explained</span> <span class="n">variance</span><span class="p">:</span>

            <span class="mi">0</span>   <span class="mf">8.510402</span>
            <span class="mi">1</span> <span class="mf">0.48959687</span>

<span class="n">explained</span> <span class="n">variance</span> <span class="n">ratio</span><span class="p">:</span>

             <span class="mi">0</span>   <span class="mf">0.9456003</span>
             <span class="mi">1</span> <span class="mf">0.054399658</span>

<span class="n">singular</span> <span class="n">values</span><span class="p">:</span>

           <span class="mi">0</span> <span class="mf">4.1256275</span>
           <span class="mi">1</span> <span class="mf">0.9895422</span>

<span class="n">mean</span><span class="p">:</span>

          <span class="mi">0</span> <span class="mf">2.6666667</span>
          <span class="mi">1</span> <span class="mf">2.3333333</span>
          <span class="mi">2</span> <span class="mf">2.3333333</span>

<span class="n">noise</span> <span class="n">variance</span><span class="p">:</span>

      <span class="mi">0</span>  <span class="mf">0.0</span>

<span class="n">transformed</span> <span class="n">matrix</span><span class="p">:</span>
             <span class="mi">0</span>           <span class="mi">1</span>
             <span class="mi">0</span>   <span class="o">-</span><span class="mf">2.8547091</span> <span class="o">-</span><span class="mf">0.42891636</span>
             <span class="mi">1</span> <span class="o">-</span><span class="mf">0.121316016</span>  <span class="mf">0.80743366</span>
             <span class="mi">2</span>    <span class="mf">2.9760244</span> <span class="o">-</span><span class="mf">0.37851727</span>

<span class="n">Input</span> <span class="n">Matrix</span><span class="p">:</span>
          <span class="mi">0</span>         <span class="mi">1</span>         <span class="mi">2</span>
          <span class="mi">0</span> <span class="mf">1.0000001</span> <span class="mf">3.9999993</span>       <span class="mf">4.0</span>
          <span class="mi">1</span>       <span class="mf">2.0</span> <span class="mf">2.0000002</span> <span class="mf">1.9999999</span>
          <span class="mi">2</span> <span class="mf">4.9999995</span> <span class="mf">1.0000006</span>       <span class="mf">1.0</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>components_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The top K components (VT.T[:,:n_components]) in U, S, VT = svd(X)</p>
</dd>
<dt><strong>explained_variance_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">How much each component explains the variance in the data given by S**2</p>
</dd>
<dt><strong>explained_variance_ratio_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">How much in % the variance is explained given by S**2/sum(S**2)</p>
</dd>
<dt><strong>singular_values_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The top K singular values. Remember all singular values &gt;= 0</p>
</dd>
<dt><strong>mean_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The column wise mean of X. Used to mean - center the data first.</p>
</dd>
<dt><strong>noise_variance_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float</span></dt>
<dd><p class="first last">From Bishop 1999’s Textbook. Used in later tasks like calculating the
estimated covariance of X.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.PCA.fit" title="cuml.PCA.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X[,&nbsp;_transform])</td>
<td>Fit the model with X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.PCA.fit_transform" title="cuml.PCA.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(self,&nbsp;X[,&nbsp;y])</td>
<td>Fit the model with X and apply the dimensionality reduction on X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.PCA.get_params" title="cuml.PCA.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[,&nbsp;deep])</td>
<td>Sklearn style return parameter state</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.PCA.inverse_transform" title="cuml.PCA.inverse_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inverse_transform</span></code></a>(self,&nbsp;X)</td>
<td>Transform data back to its original space.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.PCA.set_params" title="cuml.PCA.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self,&nbsp;**parameter)</td>
<td></td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.PCA.transform" title="cuml.PCA.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(self,&nbsp;X)</td>
<td>Apply dimensionality reduction to X.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.PCA.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em>, <em>_transform=False</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.PCA.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model with X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame</span></dt>
<dd><p class="first last">Dense matrix (floats or doubles) of shape (n_samples, n_features)</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>cluster labels</strong></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.PCA.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em>, <em>y=None</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.PCA.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model with X and apply the dimensionality reduction on X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_features)</span></dt>
<dd><p class="first last">training data (floats or doubles), where n_samples is the number of samples, and n_features is the number of features.</p>
</dd>
<dt><strong>y</strong> <span class="classifier-delimiter">:</span> <span class="classifier">ignored</span></dt>
<dd></dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X_new</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_components)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.PCA.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>self</em>, <em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.PCA.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style return parameter state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>deep</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.PCA.inverse_transform">
<code class="descname">inverse_transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.PCA.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform data back to its original space.</p>
<p>In other words, return an input X_original whose transform would be X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_components)</span></dt>
<dd><p class="first last">New data (floats or doubles), where n_samples is the number of samples and n_components is the number of components.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X_original</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_features)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.PCA.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>self</em>, <em>**parameter</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.PCA.set_params" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="cuml.PCA.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.PCA.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply dimensionality reduction to X.</p>
<p>X is projected on the first principal components previously extracted from a training set.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_features)</span></dt>
<dd><p class="first last">New data (floats or doubles), where n_samples is the number of samples and n_features is the number of features.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X_new</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_components)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="truncated-svd">
<h2>Truncated SVD<a class="headerlink" href="#truncated-svd" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.TruncatedSVD">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">TruncatedSVD</code><a class="headerlink" href="#cuml.TruncatedSVD" title="Permalink to this definition">¶</a></dt>
<dd><p>TruncatedSVD is used to compute the top K singular values and vectors of a large matrix X. 
It is much faster when n_components is small, such as in the use of PCA when 3 components is 
used for 3D visualization.</p>
<p>cuML’s TruncatedSVD expects a cuDF DataFrame, and provides 2 algorithms Full and Jacobi.
Full (default) uses a full eigendecomposition then selects the top K singular vectors. 
The Jacobi algorithm is much faster as it iteratively tries to correct the top K singular
vectors, but might be less accurate.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_components</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 1)</span></dt>
<dd><p class="first last">The number of top K singular vectors / values you want. Must be &lt;= number(columns).</p>
</dd>
<dt><strong>algorithm</strong> <span class="classifier-delimiter">:</span> <span class="classifier">‘full’ or ‘jacobi’ or ‘auto’ (default = ‘full’)</span></dt>
<dd><p class="first last">Full uses a eigendecomposition of the covariance matrix then discards components.
Jacobi is much faster as it iteratively corrects, but is less accurate.</p>
</dd>
<dt><strong>n_iter</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int (default = 15)</span></dt>
<dd><p class="first last">Used in Jacobi solver. The more iterations, the more accurate, but the slower.</p>
</dd>
<dt><strong>tol</strong> <span class="classifier-delimiter">:</span> <span class="classifier">float (default = 1e-7)</span></dt>
<dd><p class="first last">Used if algorithm = “jacobi”. The smaller the tolerance, the more accurate,
but the more slower the algorithm will get to converge.</p>
</dd>
<dt><strong>random_state</strong> <span class="classifier-delimiter">:</span> <span class="classifier">int / None (default = None)</span></dt>
<dd><p class="first last">If you want results to be the same when you restart Python, select a state.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>TruncatedSVD (the randomized version [Jacobi]) is fantastic when the number of components
you want is much smaller than the number of features. The approximation to the largest
singular values and vectors is very robust, however, this method loses a lot of accuracy
when you want many many components.</p>
<p><strong>Applications of TruncatedSVD</strong></p>
<blockquote>
<div>TruncatedSVD is also known as Latent Semantic Indexing (LSI) which tries to find topics of a
word count matrix. If X previously was centered with mean removal, TruncatedSVD is the 
same as TruncatedPCA. TruncatedSVD is also used in information retrieval tasks, recommendation
systems and data compression.</div></blockquote>
<p>For additional examples, see <a class="reference external" href="https://github.com/rapidsai/notebooks/blob/master/cuml/tsvd_demo.ipynb">the Truncated SVD  notebook</a>. 
For additional documentation, see <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html">scikitlearn’s TruncatedSVD docs</a>.</p>
<p class="rubric">Examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Both import methods supported</span>
<span class="kn">from</span> <span class="nn">cuml</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>
<span class="kn">from</span> <span class="nn">cuml.decomposition</span> <span class="kn">import</span> <span class="n">TruncatedSVD</span>

<span class="kn">import</span> <span class="nn">cudf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">gdf_float</span> <span class="o">=</span> <span class="n">cudf</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;0&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">5.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">gdf_float</span><span class="p">[</span><span class="s1">&#39;2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([</span><span class="mf">4.0</span><span class="p">,</span><span class="mf">2.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">tsvd_float</span> <span class="o">=</span> <span class="n">TruncatedSVD</span><span class="p">(</span><span class="n">n_components</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="n">algorithm</span> <span class="o">=</span> <span class="s2">&quot;jacobi&quot;</span><span class="p">,</span> <span class="n">n_iter</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="mf">1e-9</span><span class="p">)</span>
<span class="n">tsvd_float</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;components: {tsvd_float.components_}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;explained variance: {tsvd_float.explained_variance_}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;explained variance ratio: {tsvd_float.explained_variance_ratio_}&#39;</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;singular values: {tsvd_float.singular_values_}&#39;</span><span class="p">)</span>

<span class="n">trans_gdf_float</span> <span class="o">=</span> <span class="n">tsvd_float</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">gdf_float</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Transformed matrix: {trans_gdf_float}&#39;</span><span class="p">)</span>

<span class="n">input_gdf_float</span> <span class="o">=</span> <span class="n">tsvd_float</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">trans_gdf_float</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Input matrix: {input_gdf_float}&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Output:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">components</span><span class="p">:</span>            <span class="mi">0</span>           <span class="mi">1</span>          <span class="mi">2</span>
<span class="mi">0</span> <span class="mf">0.58725953</span>  <span class="mf">0.57233137</span>  <span class="mf">0.5723314</span>
<span class="mi">1</span> <span class="mf">0.80939883</span> <span class="o">-</span><span class="mf">0.41525528</span> <span class="o">-</span><span class="mf">0.4152552</span>
<span class="n">explained</span> <span class="n">variance</span><span class="p">:</span>
<span class="mi">0</span>  <span class="mf">55.33908</span>
<span class="mi">1</span> <span class="mf">16.660923</span>

<span class="n">explained</span> <span class="n">variance</span> <span class="n">ratio</span><span class="p">:</span>
<span class="mi">0</span>  <span class="mf">0.7685983</span>
<span class="mi">1</span> <span class="mf">0.23140171</span>

<span class="n">singular</span> <span class="n">values</span><span class="p">:</span>
<span class="mi">0</span>  <span class="mf">7.439024</span>
<span class="mi">1</span> <span class="mf">4.0817795</span>

<span class="n">Transformed</span> <span class="n">matrix</span><span class="p">:</span>           <span class="mi">0</span>            <span class="mi">1</span>
<span class="mi">0</span> <span class="mf">5.1659107</span>    <span class="o">-</span><span class="mf">2.512643</span>
<span class="mi">1</span> <span class="mf">3.4638448</span> <span class="o">-</span><span class="mf">0.042223275</span>                                                                                                                     <span class="mi">2</span> <span class="mf">4.0809603</span>    <span class="mf">3.2164836</span>

<span class="n">Input</span> <span class="n">matrix</span><span class="p">:</span>           <span class="mi">0</span>         <span class="mi">1</span>         <span class="mi">2</span>
<span class="mi">0</span>       <span class="mf">1.0</span>  <span class="mf">4.000001</span>  <span class="mf">4.000001</span>
<span class="mi">1</span> <span class="mf">2.0000005</span> <span class="mf">2.0000005</span> <span class="mf">2.0000007</span>
<span class="mi">2</span>  <span class="mf">5.000001</span> <span class="mf">0.9999999</span> <span class="mf">1.0000004</span>
</pre></div>
</div>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Attributes:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>components_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The top K components (VT.T[:,:n_components]) in U, S, VT = svd(X)</p>
</dd>
<dt><strong>explained_variance_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">How much each component explains the variance in the data given by S**2</p>
</dd>
<dt><strong>explained_variance_ratio_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">How much in % the variance is explained given by S**2/sum(S**2)</p>
</dd>
<dt><strong>singular_values_</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array</span></dt>
<dd><p class="first last">The top K singular values. Remember all singular values &gt;= 0</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.TruncatedSVD.fit" title="cuml.TruncatedSVD.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X[,&nbsp;_transform])</td>
<td>Fit LSI model on training cudf DataFrame X.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.TruncatedSVD.fit_transform" title="cuml.TruncatedSVD.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(self,&nbsp;X)</td>
<td>Fit LSI model to X and perform dimensionality reduction on X.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.TruncatedSVD.get_params" title="cuml.TruncatedSVD.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a>(self[,&nbsp;deep])</td>
<td>Sklearn style return parameter state</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.TruncatedSVD.inverse_transform" title="cuml.TruncatedSVD.inverse_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">inverse_transform</span></code></a>(self,&nbsp;X)</td>
<td>Transform X back to its original space.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.TruncatedSVD.set_params" title="cuml.TruncatedSVD.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a>(self,&nbsp;**params)</td>
<td>Sklearn style set parameter state to dictionary of params.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.TruncatedSVD.transform" title="cuml.TruncatedSVD.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(self,&nbsp;X)</td>
<td>Perform dimensionality reduction on X.</td>
</tr>
</tbody>
</table>
<dl class="attribute">
<dt id="cuml.TruncatedSVD.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em>, <em>_transform=True</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.TruncatedSVD.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit LSI model on training cudf DataFrame X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, dense matrix, shape (n_samples, n_features)</span></dt>
<dd><p class="first last">Training data (floats or doubles)</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.TruncatedSVD.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.TruncatedSVD.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit LSI model to X and perform dimensionality reduction on X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X GDF</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, dense matrix, shape (n_samples, n_features)</span></dt>
<dd><p class="first last">Training data (floats or doubles)</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X_new</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_components)</span></dt>
<dd><p class="first last">Reduced version of X. This will always be a dense cuDF DataFrame</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.TruncatedSVD.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><em>self</em>, <em>deep=True</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.TruncatedSVD.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style return parameter state</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>deep</strong> <span class="classifier-delimiter">:</span> <span class="classifier">boolean (default = True)</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.TruncatedSVD.inverse_transform">
<code class="descname">inverse_transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.TruncatedSVD.inverse_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X back to its original space.</p>
<p>Returns a cuDF DataFrame X_original whose transform would be X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_components)</span></dt>
<dd><p class="first last">New data.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X_original</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_features)</span></dt>
<dd><p class="first last">Note that this is always a dense cuDF DataFrame.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.TruncatedSVD.set_params">
<code class="descname">set_params</code><span class="sig-paren">(</span><em>self</em>, <em>**params</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.TruncatedSVD.set_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Sklearn style set parameter state to dictionary of params.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>params</strong> <span class="classifier-delimiter">:</span> <span class="classifier">dict of new params</span></dt>
<dd></dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="attribute">
<dt id="cuml.TruncatedSVD.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.TruncatedSVD.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform dimensionality reduction on X.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, dense matrix, shape (n_samples, n_features)</span></dt>
<dd><p class="first last">New data.</p>
</dd>
</dl>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X_new</strong> <span class="classifier-delimiter">:</span> <span class="classifier">cuDF DataFrame, shape (n_samples, n_components)</span></dt>
<dd><p class="first last">Reduced version of X. This will always be a dense DataFrame.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="umap">
<h2>UMAP<a class="headerlink" href="#umap" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="cuml.UMAP">
<em class="property">class </em><code class="descclassname">cuml.</code><code class="descname">UMAP</code><a class="headerlink" href="#cuml.UMAP" title="Permalink to this definition">¶</a></dt>
<dd><p>Uniform Manifold Approximation and Projection
Finds a low dimensional embedding of the data that approximates
an underlying manifold.</p>
<p>Adapted from <a class="reference external" href="https://github.com/lmcinnes/umap/blob/master/umap/">https://github.com/lmcinnes/umap/blob/master/umap/</a><a class="reference internal" href="#umap">umap</a>.py</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>n_neighbors: float (optional, default 15)</strong></dt>
<dd><p class="first last">The size of local neighborhood (in terms of number of neighboring
sample points) used for manifold approximation. Larger values
result in more global views of the manifold, while smaller
values result in more local data being preserved. In general
values should be in the range 2 to 100.</p>
</dd>
<dt><strong>n_components: int (optional, default 2)</strong></dt>
<dd><p class="first last">The dimension of the space to embed into. This defaults to 2 to
provide easy visualization, but can reasonably be set to any</p>
</dd>
<dt><strong>n_epochs: int (optional, default None)</strong></dt>
<dd><p class="first last">The number of training epochs to be used in optimizing the
low dimensional embedding. Larger values result in more accurate
embeddings. If None is specified a value will be selected based on
the size of the input dataset (200 for large datasets, 500 for small).</p>
</dd>
<dt><strong>learning_rate: float (optional, default 1.0)</strong></dt>
<dd><p class="first last">The initial learning rate for the embedding optimization.</p>
</dd>
<dt><strong>init: string (optional, default ‘spectral’)</strong></dt>
<dd><dl class="first last docutils">
<dt>How to initialize the low dimensional embedding. Options are:</dt>
<dd><ul class="first last simple">
<li>‘spectral’: use a spectral embedding of the fuzzy 1-skeleton</li>
<li>‘random’: assign initial embedding positions at random.</li>
</ul>
</dd>
</dl>
</dd>
<dt><strong>min_dist: float (optional, default 0.1)</strong></dt>
<dd><p class="first last">The effective minimum distance between embedded points. Smaller values
will result in a more clustered/clumped embedding where nearby points
on the manifold are drawn closer together, while larger values will
result on a more even dispersal of points. The value should be set
relative to the <code class="docutils literal notranslate"><span class="pre">spread</span></code> value, which determines the scale at which
embedded points will be spread out.</p>
</dd>
<dt><strong>spread: float (optional, default 1.0)</strong></dt>
<dd><p class="first last">The effective scale of embedded points. In combination with <code class="docutils literal notranslate"><span class="pre">min_dist</span></code>
this determines how clustered/clumped the embedded points are.</p>
</dd>
<dt><strong>set_op_mix_ratio: float (optional, default 1.0)</strong></dt>
<dd><p class="first last">Interpolate between (fuzzy) union and intersection as the set operation
used to combine local fuzzy simplicial sets to obtain a global fuzzy
simplicial sets. Both fuzzy set operations use the product t-norm.
The value of this parameter should be between 0.0 and 1.0; a value of
1.0 will use a pure fuzzy union, while 0.0 will use a pure fuzzy
intersection.</p>
</dd>
<dt><strong>local_connectivity: int (optional, default 1)</strong></dt>
<dd><p class="first last">The local connectivity required – i.e. the number of nearest
neighbors that should be assumed to be connected at a local level.
The higher this value the more connected the manifold becomes
locally. In practice this should be not more than the local intrinsic
dimension of the manifold.</p>
</dd>
<dt><strong>repulsion_strength: float (optional, default 1.0)</strong></dt>
<dd><p class="first last">Weighting applied to negative samples in low dimensional embedding
optimization. Values higher than one will result in greater weight
being given to negative samples.</p>
</dd>
<dt><strong>negative_sample_rate: int (optional, default 5)</strong></dt>
<dd><p class="first last">The number of negative samples to select per positive sample
in the optimization process. Increasing this value will result
in greater repulsive force being applied, greater optimization
cost, but slightly more accuracy.</p>
</dd>
<dt><strong>transform_queue_size: float (optional, default 4.0)</strong></dt>
<dd><p class="first last">For transform operations (embedding new points using a trained <a href="#id11"><span class="problematic" id="id12">model_</span></a>
this will control how aggressively to search for nearest neighbors.
Larger values will result in slower performance but more accurate
nearest neighbor evaluation.</p>
</dd>
<dt><strong>a: float (optional, default None)</strong></dt>
<dd><p class="first last">More specific parameters controlling the embedding. If None these
values are set automatically as determined by <code class="docutils literal notranslate"><span class="pre">min_dist</span></code> and
<code class="docutils literal notranslate"><span class="pre">spread</span></code>.</p>
</dd>
<dt><strong>b: float (optional, default None)</strong></dt>
<dd><p class="first last">More specific parameters controlling the embedding. If None these
values are set automatically as determined by <code class="docutils literal notranslate"><span class="pre">min_dist</span></code> and
<code class="docutils literal notranslate"><span class="pre">spread</span></code>.</p>
</dd>
<dt><strong>verbose: bool (optional, default False)</strong></dt>
<dd><p class="first last">Controls verbosity of logging.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#cuml.UMAP.fit" title="cuml.UMAP.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a>(self,&nbsp;X)</td>
<td>Fit X into an embedded space.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#cuml.UMAP.fit_transform" title="cuml.UMAP.fit_transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit_transform</span></code></a>(self,&nbsp;X)</td>
<td>Fit X into an embedded space and return that transformed output.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#cuml.UMAP.transform" title="cuml.UMAP.transform"><code class="xref py py-obj docutils literal notranslate"><span class="pre">transform</span></code></a>(self,&nbsp;X)</td>
<td>Transform X into the existing embedded space and return that transformed output.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="cuml.UMAP.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.UMAP.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit X into an embedded space.
Parameters
———-
X : array, shape (n_samples, n_features) or (n_samples, n_samples)</p>
<blockquote>
<div>X contains a sample per row.</div></blockquote>
</dd></dl>

<dl class="method">
<dt id="cuml.UMAP.fit_transform">
<code class="descname">fit_transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.UMAP.fit_transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit X into an embedded space and return that transformed
output.
Parameters
———-
X : array, shape (n_samples, n_features) or (n_samples, n_samples)</p>
<blockquote>
<div>X contains a sample per row.</div></blockquote>
<dl class="docutils">
<dt>X_new <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_samples, n_components)</span></dt>
<dd>Embedding of the training data in low-dimensional space.</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="cuml.UMAP.transform">
<code class="descname">transform</code><span class="sig-paren">(</span><em>self</em>, <em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#cuml.UMAP.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform X into the existing embedded space and return that
transformed output.</p>
<p>Please refer to the reference UMAP implementation for information
on the differences between fit_transform() and running fit() transform().</p>
<p>Specifically, the transform() function is stochastic:
<a class="reference external" href="https://github.com/lmcinnes/umap/issues/158">https://github.com/lmcinnes/umap/issues/158</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><dl class="first last docutils">
<dt><strong>X</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_samples, n_features)</span></dt>
<dd><p class="first last">New data to be transformed.</p>
</dd>
<dt><strong>Returns</strong></dt>
<dd></dd>
<dt><strong>——-</strong></dt>
<dd></dd>
<dt><strong>X_new</strong> <span class="classifier-delimiter">:</span> <span class="classifier">array, shape (n_samples, n_components)</span></dt>
<dd><p class="first last">Embedding of the new data in low-dimensional space.</p>
</dd>
</dl>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="index.html" class="btn btn-neutral float-left" title="Welcome to cuML’s documentation!" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, nvidia

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>