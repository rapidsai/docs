<!DOCTYPE html>
<html class="writer-html5" lang="en"><head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <title>dask_cuda.local_cuda_cluster &mdash; dask-cuda 22.12.00a0+g8c87288 documentation</title>
      <link href="../../_static/pygments.css" rel="stylesheet" type="text/css">
      <link href="../../_static/css/theme.css" rel="stylesheet" type="text/css">
      <link href="https://docs.rapids.ai/assets/css/custom.css" rel="stylesheet" type="text/css">
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
        <script defer="defer" src="https://docs.rapids.ai/assets/js/custom.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link href="../../genindex.html" rel="index" title="Index">
    <link href="../../search.html" rel="search" title="Search"> 
<script id="rapids-selector-pixel-src" src="https://assets.adobedtm.com/5d4962a43b79/814eb6e9b4e1/launch-4bc07f1e0b0b.min.js"></script><link href="/assets/css/custom.css" id="rapids-selector-css" rel="stylesheet"></head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav class="wy-nav-side" data-toggle="wy-nav-shift">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"><div id="rapids-jtd-container"><div class="rapids-home-container"><a class="rapids-home-container__home-btn" href="/api">Home</a></div><div class="rapids-selector__container rapids-selector--hidden"><div class="rapids-selector__selected">dask-cuda</div><div class="rapids-selector__menu"><a class="rapids-selector__menu-item" href="/api/clx/stable/api.html">clx</a><a class="rapids-selector__menu-item" href="/api/cucim/stable/api.html">cucim</a><a class="rapids-selector__menu-item" href="/api/cudf-java/stable">cudf-java</a><a class="rapids-selector__menu-item" href="/api/cudf/stable/index.html">cudf</a><a class="rapids-selector__menu-item" href="/api/cugraph/stable">cugraph</a><a class="rapids-selector__menu-item" href="/api/cuml/stable/api.html">cuml</a><a class="rapids-selector__menu-item" href="/api/cusignal/stable/api.html">cusignal</a><a class="rapids-selector__menu-item" href="/api/cuspatial/stable">cuspatial</a><a class="rapids-selector__menu-item" href="/api/cuxfilter/stable">cuxfilter</a><a class="rapids-selector__menu-item rapids-selector__menu-item--selected" href="/api/dask-cuda/stable/api.html">dask-cuda</a><a class="rapids-selector__menu-item" href="/api/kvikio/stable/api.html">kvikio</a><a class="rapids-selector__menu-item" href="/api/libcudf/stable/namespacecudf.html">libcudf</a><a class="rapids-selector__menu-item" href="/api/libcugraph/stable">libcugraph</a><a class="rapids-selector__menu-item" href="/api/libcuml/stable">libcuml</a><a class="rapids-selector__menu-item" href="/api/libcuspatial/stable">libcuspatial</a><a class="rapids-selector__menu-item" href="/api/libkvikio/stable">libkvikio</a><a class="rapids-selector__menu-item" href="/api/librmm/stable/annotated.html">librmm</a><a class="rapids-selector__menu-item" href="/api/raft/stable">raft</a><a class="rapids-selector__menu-item" href="/api/rapids-cmake/stable/api.html">rapids-cmake</a><a class="rapids-selector__menu-item" href="/api/rmm/stable/api.html">rmm</a></div></div><div class="rapids-selector__container rapids-selector--hidden"><div class="rapids-selector__selected">legacy (22.12)</div><div class="rapids-selector__menu"><a class="rapids-selector__menu-item" href="/api/dask-cuda/nightly/api.html">nightly (23.04)</a><a class="rapids-selector__menu-item" href="/api/dask-cuda/stable/api.html">stable (23.02)</a><a class="rapids-selector__menu-item rapids-selector__menu-item--selected" href="/api/dask-cuda/legacy/api.html">legacy (22.12)</a></div></div></div>
            
              
<div role="search">
  <form action="../../search.html" class="wy-form" id="rtd-search-form" method="get">
    <input name="q" placeholder="Search docs" type="text">
    <input name="check_keywords" type="hidden" value="yes">
    <input name="area" type="hidden" value="default">
  </form>
</div>
        </div><div aria-label="Navigation menu" class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../install.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../troubleshooting.html">Troubleshooting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api.html">API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Additional Features</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ucx.html">UCX Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../explicit_comms.html">Explicit-comms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../spilling.html">Spilling from device</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../examples/best-practices.html">Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/worker_count.html">Controlling number of workers</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../examples/ucx.html">Enabling UCX communication</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section class="wy-nav-content-wrap" data-toggle="wy-nav-shift"><nav aria-label="Mobile navigation menu" class="wy-nav-top">
          <i class="fa fa-bars" data-toggle="wy-nav-top"></i>
          <a href="../../index.html">dask-cuda</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div aria-label="Page navigation" role="navigation">
  <ul class="wy-breadcrumbs">
      <li><a class="icon icon-home" href="../../index.html"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">dask_cuda.local_cuda_cluster</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr>
</div>
          <div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
           <div itemprop="articleBody">
             
  <h1>Source code for dask_cuda.local_cuda_cluster</h1><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">dask</span>
<span class="kn">from</span> <span class="nn">distributed</span> <span class="kn">import</span> <span class="n">LocalCluster</span><span class="p">,</span> <span class="n">Nanny</span><span class="p">,</span> <span class="n">Worker</span>
<span class="kn">from</span> <span class="nn">distributed.utils</span> <span class="kn">import</span> <span class="n">has_arg</span>
<span class="kn">from</span> <span class="nn">distributed.worker_memory</span> <span class="kn">import</span> <span class="n">parse_memory_limit</span>

<span class="kn">from</span> <span class="nn">.device_host_file</span> <span class="kn">import</span> <span class="n">DeviceHostFile</span>
<span class="kn">from</span> <span class="nn">.initialize</span> <span class="kn">import</span> <span class="n">initialize</span>
<span class="kn">from</span> <span class="nn">.proxify_host_file</span> <span class="kn">import</span> <span class="n">ProxifyHostFile</span>
<span class="kn">from</span> <span class="nn">.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">CPUAffinity</span><span class="p">,</span>
    <span class="n">PreImport</span><span class="p">,</span>
    <span class="n">RMMSetup</span><span class="p">,</span>
    <span class="n">cuda_visible_devices</span><span class="p">,</span>
    <span class="n">get_cpu_affinity</span><span class="p">,</span>
    <span class="n">get_ucx_config</span><span class="p">,</span>
    <span class="n">nvml_device_index</span><span class="p">,</span>
    <span class="n">parse_cuda_visible_device</span><span class="p">,</span>
    <span class="n">parse_device_memory_limit</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">class</span> <span class="nc">LoggedWorker</span><span class="p">(</span><span class="n">Worker</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">async</span> <span class="k">def</span> <span class="nf">start</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">await</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">set_address</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">address</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LoggedNanny</span><span class="p">(</span><span class="n">Nanny</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">worker_class</span><span class="o">=</span><span class="n">LoggedWorker</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<div class="viewcode-block" id="LocalCUDACluster"><a class="viewcode-back" href="../../api.html#dask_cuda.LocalCUDACluster">[docs]</a><span class="k">class</span> <span class="nc">LocalCUDACluster</span><span class="p">(</span><span class="n">LocalCluster</span><span class="p">):</span>
    <span class="sd">"""A variant of ``dask.distributed.LocalCluster`` that uses one GPU per process.</span>

<span class="sd">    This assigns a different ``CUDA_VISIBLE_DEVICES`` environment variable to each Dask</span>
<span class="sd">    worker process.</span>

<span class="sd">    For machines with a complex architecture mapping CPUs, GPUs, and network hardware,</span>
<span class="sd">    such as NVIDIA DGX-1 and DGX-2, this class creates a local cluster that tries to</span>
<span class="sd">    respect this hardware as much as possible.</span>

<span class="sd">    Each worker process is automatically assigned the correct CPU cores and network</span>
<span class="sd">    interface cards to maximize performance. If UCX and UCX-Py are available, InfiniBand</span>
<span class="sd">    and NVLink connections can be used to optimize data transfer performance.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    CUDA_VISIBLE_DEVICES : str, list of int, or None, default None</span>
<span class="sd">        GPUs to restrict activity to. Can be a string (like ``"0,1,2,3"``), list (like</span>
<span class="sd">        ``[0, 1, 2, 3]``), or ``None`` to use all available GPUs.</span>
<span class="sd">    n_workers : int or None, default None</span>
<span class="sd">        Number of workers. Can be an integer or ``None`` to fall back on the GPUs</span>
<span class="sd">        specified by ``CUDA_VISIBLE_DEVICES``. The value of ``n_workers`` must be</span>
<span class="sd">        smaller or equal to the number of GPUs specified in ``CUDA_VISIBLE_DEVICES``</span>
<span class="sd">        when the latter is specified, and if smaller, only the first ``n_workers`` GPUs</span>
<span class="sd">        will be used.</span>
<span class="sd">    threads_per_worker : int, default 1</span>
<span class="sd">        Number of threads to be used for each Dask worker process.</span>
<span class="sd">    memory_limit : int, float, str, or None, default "auto"</span>
<span class="sd">        Bytes of memory per process that the worker can use. Can be an integer (bytes),</span>
<span class="sd">        float (fraction of total system memory), string (like ``"5GB"`` or ``"5000M"``),</span>
<span class="sd">        or ``"auto"``, 0, or ``None`` for no memory management.</span>
<span class="sd">    device_memory_limit : int, float, str, or None, default 0.8</span>
<span class="sd">        Size of the CUDA device LRU cache, which is used to determine when the worker</span>
<span class="sd">        starts spilling to host memory. Can be an integer (bytes), float (fraction of</span>
<span class="sd">        total device memory), string (like ``"5GB"`` or ``"5000M"``), or ``"auto"``, 0,</span>
<span class="sd">        or ``None`` to disable spilling to host (i.e. allow full device memory usage).</span>
<span class="sd">    local_directory : str or None, default None</span>
<span class="sd">        Path on local machine to store temporary files. Can be a string (like</span>
<span class="sd">        ``"path/to/files"``) or ``None`` to fall back on the value of</span>
<span class="sd">        ``dask.temporary-directory`` in the local Dask configuration, using the current</span>
<span class="sd">        working directory if this is not set.</span>
<span class="sd">    shared_filesystem: bool or None, default None</span>
<span class="sd">        Whether the `local_directory` above is shared between all workers or not.</span>
<span class="sd">        If ``None``, the "jit-unspill-shared-fs" config value are used, which</span>
<span class="sd">        defaults to True. Notice, in all other cases this option defaults to False,</span>
<span class="sd">        but on a local cluster it defaults to True -- we assume all workers use the</span>
<span class="sd">        same filesystem.</span>
<span class="sd">    protocol : str or None, default None</span>
<span class="sd">        Protocol to use for communication. Can be a string (like ``"tcp"`` or</span>
<span class="sd">        ``"ucx"``), or ``None`` to automatically choose the correct protocol.</span>
<span class="sd">    enable_tcp_over_ucx : bool, default None</span>
<span class="sd">        Set environment variables to enable TCP over UCX, even if InfiniBand and NVLink</span>
<span class="sd">        are not supported or disabled.</span>
<span class="sd">    enable_infiniband : bool, default None</span>
<span class="sd">        Set environment variables to enable UCX over InfiniBand, requires</span>
<span class="sd">        ``protocol="ucx"`` and implies ``enable_tcp_over_ucx=True`` when ``True``.</span>
<span class="sd">    enable_nvlink : bool, default None</span>
<span class="sd">        Set environment variables to enable UCX over NVLink, requires ``protocol="ucx"``</span>
<span class="sd">        and implies ``enable_tcp_over_ucx=True`` when ``True``.</span>
<span class="sd">    enable_rdmacm : bool, default None</span>
<span class="sd">        Set environment variables to enable UCX RDMA connection manager support,</span>
<span class="sd">        requires ``protocol="ucx"`` and ``enable_infiniband=True``.</span>
<span class="sd">    rmm_pool_size : int, str or None, default None</span>
<span class="sd">        RMM pool size to initialize each worker with. Can be an integer (bytes), float</span>
<span class="sd">        (fraction of total device memory), string (like ``"5GB"`` or ``"5000M"``), or</span>
<span class="sd">        ``None`` to disable RMM pools.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This size is a per-worker configuration, and not cluster-wide.</span>
<span class="sd">    rmm_maximum_pool_size : int, str or None, default None</span>
<span class="sd">        When ``rmm_pool_size`` is set, this argument indicates</span>
<span class="sd">        the maximum pool size.</span>
<span class="sd">        Can be an integer (bytes), float (fraction of total device memory), string</span>
<span class="sd">        (like ``"5GB"`` or ``"5000M"``) or ``None``. By default, the total available</span>
<span class="sd">        memory on the GPU is used. ``rmm_pool_size`` must be specified to use RMM pool</span>
<span class="sd">        and to set the maximum pool size.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This size is a per-worker configuration, and not cluster-wide.</span>
<span class="sd">    rmm_managed_memory : bool, default False</span>
<span class="sd">        Initialize each worker with RMM and set it to use managed memory. If disabled,</span>
<span class="sd">        RMM may still be used by specifying ``rmm_pool_size``.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            Managed memory is currently incompatible with NVLink. Trying to enable both</span>
<span class="sd">            will result in an exception.</span>
<span class="sd">    rmm_async: bool, default False</span>
<span class="sd">        Initialize each worker withh RMM and set it to use RMM's asynchronous allocator.</span>
<span class="sd">        See ``rmm.mr.CudaAsyncMemoryResource`` for more info.</span>

<span class="sd">        .. warning::</span>
<span class="sd">            The asynchronous allocator requires CUDA Toolkit 11.2 or newer. It is also</span>
<span class="sd">            incompatible with RMM pools and managed memory. Trying to enable both will</span>
<span class="sd">            result in an exception.</span>
<span class="sd">    rmm_log_directory : str or None, default None</span>
<span class="sd">        Directory to write per-worker RMM log files to. The client and scheduler are not</span>
<span class="sd">        logged here. Can be a string (like ``"/path/to/logs/"``) or ``None`` to</span>
<span class="sd">        disable logging.</span>

<span class="sd">        .. note::</span>
<span class="sd">            Logging will only be enabled if ``rmm_pool_size`` is specified or</span>
<span class="sd">            ``rmm_managed_memory=True``.</span>
<span class="sd">    rmm_track_allocations : bool, default False</span>
<span class="sd">        If True, wraps the memory resource used by each worker with a</span>
<span class="sd">        ``rmm.mr.TrackingResourceAdaptor``, which tracks the amount of</span>
<span class="sd">        memory allocated.</span>

<span class="sd">        .. note::</span>
<span class="sd">             This option enables additional diagnostics to be collected and</span>
<span class="sd">             reported by the Dask dashboard. However, there is significant overhead</span>
<span class="sd">             associated with this and it should only be used for debugging and</span>
<span class="sd">             memory profiling.</span>
<span class="sd">    jit_unspill : bool or None, default None</span>
<span class="sd">        Enable just-in-time unspilling. Can be a boolean or ``None`` to fall back on</span>
<span class="sd">        the value of ``dask.jit-unspill`` in the local Dask configuration, disabling</span>
<span class="sd">        unspilling if this is not set.</span>

<span class="sd">        .. note::</span>
<span class="sd">            This is experimental and doesn't support memory spilling to disk. See</span>
<span class="sd">            ``proxy_object.ProxyObject`` and ``proxify_host_file.ProxifyHostFile`` for</span>
<span class="sd">            more info.</span>
<span class="sd">    log_spilling : bool, default True</span>
<span class="sd">        Enable logging of spilling operations directly to ``distributed.Worker`` with an</span>
<span class="sd">        ``INFO`` log level.</span>
<span class="sd">    pre_import : str, list or None, default None</span>
<span class="sd">        Pre-import libraries as a Worker plugin to prevent long import times bleeding</span>
<span class="sd">        through later Dask operations. Should be a list of comma-separated names,</span>
<span class="sd">        such as "cudf,rmm" or a list of strings such as ["cudf", "rmm"].</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from dask_cuda import LocalCUDACluster</span>
<span class="sd">    &gt;&gt;&gt; from dask.distributed import Client</span>
<span class="sd">    &gt;&gt;&gt; cluster = LocalCUDACluster()</span>
<span class="sd">    &gt;&gt;&gt; client = Client(cluster)</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    TypeError</span>
<span class="sd">        If InfiniBand or NVLink are enabled and ``protocol!="ucx"``.</span>
<span class="sd">    ValueError</span>
<span class="sd">        If NVLink and RMM managed memory are both enabled, or if RMM pools / managed</span>
<span class="sd">        memory and asynchronous allocator are both enabled.</span>

<span class="sd">    See Also</span>
<span class="sd">    --------</span>
<span class="sd">    LocalCluster</span>
<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_workers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">threads_per_worker</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">memory_limit</span><span class="o">=</span><span class="s2">"auto"</span><span class="p">,</span>
        <span class="n">device_memory_limit</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
        <span class="n">data</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">local_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">shared_filesystem</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">protocol</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">enable_tcp_over_ucx</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">enable_infiniband</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">enable_nvlink</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">enable_rdmacm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">rmm_pool_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">rmm_maximum_pool_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">rmm_managed_memory</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">rmm_async</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">rmm_log_directory</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">rmm_track_allocations</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">jit_unspill</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">log_spilling</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">worker_class</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">pre_import</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="c1"># Required by RAPIDS libraries (e.g., cuDF) to ensure no context</span>
        <span class="c1"># initialization happens before we can set CUDA_VISIBLE_DEVICES</span>
        <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">"RAPIDS_NO_INITIALIZE"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"True"</span>

        <span class="k">if</span> <span class="n">threads_per_worker</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"threads_per_worker must be higher than 0."</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">CUDA_VISIBLE_DEVICES</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">CUDA_VISIBLE_DEVICES</span> <span class="o">=</span> <span class="n">cuda_visible_devices</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">CUDA_VISIBLE_DEVICES</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">CUDA_VISIBLE_DEVICES</span> <span class="o">=</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">","</span><span class="p">)</span>
        <span class="n">CUDA_VISIBLE_DEVICES</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span>
            <span class="nb">map</span><span class="p">(</span><span class="n">parse_cuda_visible_device</span><span class="p">,</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">n_workers</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">n_workers</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">CUDA_VISIBLE_DEVICES</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_workers</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"Number of workers cannot be less than 1."</span><span class="p">)</span>
        <span class="c1"># Set nthreads=1 when parsing mem_limit since it only depends on n_workers</span>
        <span class="k">if</span> <span class="n">has_arg</span><span class="p">(</span><span class="n">parse_memory_limit</span><span class="p">,</span> <span class="s2">"logger"</span><span class="p">):</span>
            <span class="c1"># TODO: Remove has_arg check after 2022.11.1 support is dropped</span>
            <span class="n">logger</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory_limit</span> <span class="o">=</span> <span class="n">parse_memory_limit</span><span class="p">(</span>
                <span class="n">memory_limit</span><span class="o">=</span><span class="n">memory_limit</span><span class="p">,</span>
                <span class="n">nthreads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">total_cores</span><span class="o">=</span><span class="n">n_workers</span><span class="p">,</span>
                <span class="n">logger</span><span class="o">=</span><span class="n">logger</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">memory_limit</span> <span class="o">=</span> <span class="n">parse_memory_limit</span><span class="p">(</span>
                <span class="n">memory_limit</span><span class="o">=</span><span class="n">memory_limit</span><span class="p">,</span> <span class="n">nthreads</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">total_cores</span><span class="o">=</span><span class="n">n_workers</span>
            <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device_memory_limit</span> <span class="o">=</span> <span class="n">parse_device_memory_limit</span><span class="p">(</span>
            <span class="n">device_memory_limit</span><span class="p">,</span> <span class="n">device_index</span><span class="o">=</span><span class="n">nvml_device_index</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">CUDA_VISIBLE_DEVICES</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_pool_size</span> <span class="o">=</span> <span class="n">rmm_pool_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_maximum_pool_size</span> <span class="o">=</span> <span class="n">rmm_maximum_pool_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_managed_memory</span> <span class="o">=</span> <span class="n">rmm_managed_memory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_async</span> <span class="o">=</span> <span class="n">rmm_async</span>
        <span class="k">if</span> <span class="n">rmm_pool_size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">rmm_managed_memory</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="kn">import</span> <span class="nn">rmm</span>  <span class="c1"># noqa F401</span>
            <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">"RMM pool or managed memory requested but module 'rmm' "</span>
                    <span class="s2">"is not available. For installation instructions, please "</span>
                    <span class="s2">"see https://github.com/rapidsai/rmm"</span>
                <span class="p">)</span>  <span class="c1"># pragma: no cover</span>
            <span class="k">if</span> <span class="n">rmm_async</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">"RMM pool and managed memory are incompatible with asynchronous "</span>
                    <span class="s2">"allocator"</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">enable_nvlink</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">"When using NVLink we recommend setting a "</span>
                    <span class="s2">"`rmm_pool_size`. Please see: "</span>
                    <span class="s2">"https://dask-cuda.readthedocs.io/en/latest/ucx.html"</span>
                    <span class="s2">"#important-notes for more details"</span>
                <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_log_directory</span> <span class="o">=</span> <span class="n">rmm_log_directory</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_track_allocations</span> <span class="o">=</span> <span class="n">rmm_track_allocations</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"processes"</span><span class="p">,</span> <span class="kc">True</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Processes are necessary in order to use multiple GPUs with Dask"</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">shared_filesystem</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Notice, we assume a shared filesystem</span>
            <span class="n">shared_filesystem</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"jit-unspill-shared-fs"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">jit_unspill</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">jit_unspill</span> <span class="o">=</span> <span class="n">dask</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"jit-unspill"</span><span class="p">,</span> <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">"data"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">device_memory_limit</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">memory_limit</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">elif</span> <span class="n">jit_unspill</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">ProxifyHostFile</span><span class="p">,</span>
                    <span class="p">{</span>
                        <span class="s2">"device_memory_limit"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_memory_limit</span><span class="p">,</span>
                        <span class="s2">"memory_limit"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_limit</span><span class="p">,</span>
                        <span class="s2">"shared_filesystem"</span><span class="p">:</span> <span class="n">shared_filesystem</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">data</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">DeviceHostFile</span><span class="p">,</span>
                    <span class="p">{</span>
                        <span class="s2">"device_memory_limit"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">device_memory_limit</span><span class="p">,</span>
                        <span class="s2">"memory_limit"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">memory_limit</span><span class="p">,</span>
                        <span class="s2">"log_spilling"</span><span class="p">:</span> <span class="n">log_spilling</span><span class="p">,</span>
                    <span class="p">},</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">enable_tcp_over_ucx</span> <span class="ow">or</span> <span class="n">enable_infiniband</span> <span class="ow">or</span> <span class="n">enable_nvlink</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">protocol</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">protocol</span> <span class="o">=</span> <span class="s2">"ucx"</span>
            <span class="k">elif</span> <span class="n">protocol</span> <span class="o">!=</span> <span class="s2">"ucx"</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">"Enabling InfiniBand or NVLink requires protocol='ucx'"</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">host</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"host"</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="n">initialize</span><span class="p">(</span>
            <span class="n">create_cuda_context</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">enable_tcp_over_ucx</span><span class="o">=</span><span class="n">enable_tcp_over_ucx</span><span class="p">,</span>
            <span class="n">enable_nvlink</span><span class="o">=</span><span class="n">enable_nvlink</span><span class="p">,</span>
            <span class="n">enable_infiniband</span><span class="o">=</span><span class="n">enable_infiniband</span><span class="p">,</span>
            <span class="n">enable_rdmacm</span><span class="o">=</span><span class="n">enable_rdmacm</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">worker_class</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

            <span class="n">worker_class</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
                <span class="n">LoggedNanny</span> <span class="k">if</span> <span class="n">log_spilling</span> <span class="ow">is</span> <span class="kc">True</span> <span class="k">else</span> <span class="n">Nanny</span><span class="p">,</span>
                <span class="n">worker_class</span><span class="o">=</span><span class="n">worker_class</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">pre_import</span> <span class="o">=</span> <span class="n">pre_import</span>

        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">threads_per_worker</span><span class="o">=</span><span class="n">threads_per_worker</span><span class="p">,</span>
            <span class="n">memory_limit</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">memory_limit</span><span class="p">,</span>
            <span class="n">processes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">local_directory</span><span class="o">=</span><span class="n">local_directory</span><span class="p">,</span>
            <span class="n">protocol</span><span class="o">=</span><span class="n">protocol</span><span class="p">,</span>
            <span class="n">worker_class</span><span class="o">=</span><span class="n">worker_class</span><span class="p">,</span>
            <span class="n">config</span><span class="o">=</span><span class="p">{</span>
                <span class="s2">"distributed.comm.ucx"</span><span class="p">:</span> <span class="n">get_ucx_config</span><span class="p">(</span>
                    <span class="n">enable_tcp_over_ucx</span><span class="o">=</span><span class="n">enable_tcp_over_ucx</span><span class="p">,</span>
                    <span class="n">enable_nvlink</span><span class="o">=</span><span class="n">enable_nvlink</span><span class="p">,</span>
                    <span class="n">enable_infiniband</span><span class="o">=</span><span class="n">enable_infiniband</span><span class="p">,</span>
                    <span class="n">enable_rdmacm</span><span class="o">=</span><span class="n">enable_rdmacm</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">},</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">new_spec</span><span class="p">[</span><span class="s2">"options"</span><span class="p">][</span><span class="s2">"preload"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_spec</span><span class="p">[</span><span class="s2">"options"</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">"preload"</span><span class="p">,</span> <span class="p">[]</span>
        <span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s2">"dask_cuda.initialize"</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_spec</span><span class="p">[</span><span class="s2">"options"</span><span class="p">][</span><span class="s2">"preload_argv"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_spec</span><span class="p">[</span><span class="s2">"options"</span><span class="p">]</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="s2">"preload_argv"</span><span class="p">,</span> <span class="p">[]</span>
        <span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="s2">"--create-cuda-context"</span><span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">cuda_visible_devices</span> <span class="o">=</span> <span class="n">CUDA_VISIBLE_DEVICES</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="n">n_workers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sync</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_correct_state</span><span class="p">)</span>

<div class="viewcode-block" id="LocalCUDACluster.new_worker_spec"><a class="viewcode-back" href="../../api.html#dask_cuda.LocalCUDACluster.new_worker_spec">[docs]</a>    <span class="k">def</span> <span class="nf">new_worker_spec</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cuda_visible_devices</span><span class="p">)</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">worker_spec</span><span class="p">))</span>
        <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">"Can not scale beyond visible devices"</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cuda_visible_devices</span>
            <span class="p">)</span>

        <span class="n">spec</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_spec</span><span class="p">)</span>
        <span class="n">worker_count</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cuda_visible_devices</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="n">visible_devices</span> <span class="o">=</span> <span class="n">cuda_visible_devices</span><span class="p">(</span><span class="n">worker_count</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cuda_visible_devices</span><span class="p">)</span>
        <span class="n">spec</span><span class="p">[</span><span class="s2">"options"</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s2">"env"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="s2">"CUDA_VISIBLE_DEVICES"</span><span class="p">:</span> <span class="n">visible_devices</span><span class="p">,</span>
                <span class="p">},</span>
                <span class="s2">"plugins"</span><span class="p">:</span> <span class="p">{</span>
                    <span class="n">CPUAffinity</span><span class="p">(</span>
                        <span class="n">get_cpu_affinity</span><span class="p">(</span><span class="n">nvml_device_index</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">visible_devices</span><span class="p">))</span>
                    <span class="p">),</span>
                    <span class="n">RMMSetup</span><span class="p">(</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_pool_size</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_maximum_pool_size</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_managed_memory</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_async</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_log_directory</span><span class="p">,</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">rmm_track_allocations</span><span class="p">,</span>
                    <span class="p">),</span>
                    <span class="n">PreImport</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">pre_import</span><span class="p">),</span>
                <span class="p">},</span>
            <span class="p">}</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">spec</span><span class="p">}</span></div></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr>

  <div role="contentinfo">
    <p>&copy; Copyright 2020-2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 


<script defer id="rapids-selector-js" src="/assets/js/custom.js"></script><script id="rapids-selector-pixel-invocation" type="text/javascript">_satellite.pageBottom();</script></body></html>